
# coding: utf-8

# <h1>Lesson 5. Model selection: US Salary Prediction</h1>

# <img src=https://upload.wikimedia.org/wikipedia/commons/thumb/9/93/White_House_lawn_%281%29.tif/lossy-page1-2433px-White_House_lawn_%281%29.tif.jpg style="height:300px;">
#   
# <p>In this exercise you will use the US Adult Census data relating income to social factors such as Age, Education, race etc...</p>
# 
# <p>The goal here is to train a binary classifier on the training dataset to predict the column income_bracket which has two possible values ">50K" and "<=50K" and evaluate the accuracy of the classifier with the test dataset.</p>
# 

# In[12]:


import pandas as pd
import numpy as np
from sklearn import preprocessing, metrics
from sklearn.model_selection import train_test_split


train=pd.read_csv('census-training.csv')
print(train.info())
train.head(20)


# <h3>Q.1. Write a command that will calculate the number of unique values for each feature in the training data.</h3>

# In[13]:


#TODO
print('Unique values per feature:')
train.nunique(axis=0)


# <h3>Q.2. There is a special character '?' inserted in the data in place of null values.  Write a command that will remove it and replace with NaN.</h3>

# In[14]:


# Command (s): remove the '?' special character and replace with NaN
#TODO
train=pd.read_csv('census-training.csv',na_values=['?'])

train.isnull().sum() #checking the dataset for NaN values .... NaN values in two columns


# <h3>Q.3. Replace all missing values in Occupation and Country by their mode (most occuring values). </h3>

# In[15]:


#Command(s):
train.mode() # finding mode to compute the most occuring item in every column
#replace missing values with their mode
#TODO
train = train.fillna(train.mode().iloc[0])

train.isnull().sum() #checking the data for NaN values .... should all show 0 now


# <h3>Q.4. Write functions to replace Gender and Income attributes to "0" and "1". </h3>

# In[16]:


# converting Gender to "0" and "1" 
def gender_to_numeric(x):
    if x == 'Male':
        x = 1
    else:
        x = 0
    return x
    
train['Gender'] = train['Gender'].apply(lambda x: gender_to_numeric(x))

# converting Inccome to "0" and "1" 
def income_to_numeric(x):
    if x == '>50K.':
        x = 1
    else:
        x = 0
    return x

train['Income'] = train['Income'].apply(lambda x: income_to_numeric(x))

train.head(10)


# <h3>Q.5. Use the label encoder API to encode all object-type in the data. </h3>

# In[17]:


# Command(s) 
obj = train.select_dtypes(include=['object']) #all features that are 'object' datatypes
le = preprocessing.LabelEncoder()
for i in range(len(obj.columns)):
    train[obj.columns[i]] = le.fit_transform(train[obj.columns[i]]) #TODO  #Encode input data
    
train.head(10) #Inspect the data, all features should be numeric now


# <h3>Q.6. Split the data into 70% training and 30% test </h3>

# In[22]:


target_y = 'Income'
features = list(train.drop(target_y,axis=1).columns.values)

X = train[features]
y = train[target_y]

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.3,random_state=21)


# <h3>Q.7. Train the logistic regression model on the train dataset and evaluate its performance on the test dataset.</p>

# In[23]:


#Initialize classifier
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import confusion_matrix, classification_report, roc_curve, roc_auc_score,accuracy_score, auc

log_rgr = LogisticRegression()#TODO Initialize logistic regression classifier

log_rgr = log_rgr.fit(X_train,y_train)
# TODO: fit X_train and y_train

#predict on the test set
y_pred = log_rgr.predict(X_test)
lr_acc = accuracy_score(y_test,y_pred) #TODO: Compute the accuracy score
# # calculate the fpr and tpr for all thresholds of the classification
probs = log_rgr.predict_proba(X_test)
preds = probs[:,1]
fpr, tpr, threshold = metrics.roc_curve(y_test, preds)
roc_auc = auc(fpr,tpr) #TODO
print("Accuracy: {}".format(lr_acc))
print("AUC: {}".format(roc_auc))

# # Plot the ROC curve
import matplotlib.pyplot as plt
plt.title('Receiver Operating Characteristic')
plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)
plt.legend(loc = 'lower right')
plt.plot([0, 1], [0, 1],'r--')
plt.xlim([0, 1])
plt.ylim([0, 1])
plt.ylabel('True Positive Rate')
plt.xlabel('False Positive Rate')
plt.show()


# <h3>Q.8. Train the KNN classifier (with k=15) on the train dataset and evaluate its performance on the test dataset. Compare your results with the one above</p>

# In[24]:


from sklearn.neighbors import KNeighborsClassifier

#Initialize the classifier
knn = KNeighborsClassifier(n_neighbors=15) #TODO Initialize KNN classifier with k=15
# TODO: fit X_train and y_train
knn.fit(X_train,y_train)

y_pred = knn.predict(X_test) #TODO 
knn_acc = accuracy_score(y_test,y_pred) #TODO: Compute the accuracy score
# calculate the fpr and tpr for all thresholds of the classification
probs = knn.predict_proba(X_test)
preds = probs[:,1]
fpr, tpr, threshold = metrics.roc_curve(y_test, preds)
roc_auc = auc(fpr,tpr) #TODO
print("Accuracy: {}".format(knn_acc))
print("AUC: {}".format(roc_auc))

# Plot the ROC curve
import matplotlib.pyplot as plt
plt.title('Receiver Operating Characteristic')
plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)
plt.legend(loc = 'lower right')
plt.plot([0, 1], [0, 1],'r--')
plt.xlim([0, 1])
plt.ylim([0, 1])
plt.ylabel('True Positive Rate')
plt.xlabel('False Positive Rate')
plt.show()

#Compare results
# The KNN classifier performs worse than the LR model. The accuracies are comparable, but the LR wins the AUC race easily.


# <h3>Q.9. Perform recursive feature elimination (5 features) on the dataset using the logistic regression classifier. Any difference in the results? Explain.</h3>

# In[25]:


from sklearn.feature_selection import RFE

feat_count = 5

mod = LogisticRegression()
rfe =  RFE(mod, feat_count)

rfe = rfe.fit(X_train,y_train)

y_pred = rfe.predict(X_test)
lr_acc = accuracy_score(y_test,y_pred)
# # calculate the fpr and tpr for all thresholds of the classification
probs = rfe.predict_proba(X_test)
preds = probs[:,1]
fpr, tpr, threshold = metrics.roc_curve(y_test, preds)
roc_auc = auc(fpr,tpr)
print("Accuracy: {}".format(lr_acc))
print("AUC: {}".format(roc_auc))


# This model performs very similarly to the full KNN model, which leads you to believe that not all features are useful.
# The implication is that several of the features in the full dataset are esentially adding very little predictive power.

